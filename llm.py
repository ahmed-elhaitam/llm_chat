import streamlit as st
import pandas as pd
from langchain_groq import ChatGroq
from langchain.schema import HumanMessage, AIMessage
from PyPDF2 import PdfReader

# Initialize LLM
llm = ChatGroq(
    model_name="llama-3.1-70b-versatile",
    groq_api_key="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",
    temperature=0
)

# Initialize session state for conversation history
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# Page configuration
st.set_page_config(
    page_title="LLM Orientation Assistant",
    page_icon="üéì",
    layout="wide"
)

# Sidebar with advanced filtering options
st.sidebar.title("üîç Filtrer les √©coles")
uploaded_file = st.sidebar.file_uploader("T√©l√©chargez un fichier PDF pour le contexte :", type=["pdf"])

if uploaded_file:
    # Read PDF content
    pdf_reader = PdfReader(uploaded_file)
    text = ""
    for page_num in range(len(pdf_reader.pages)):
        text += pdf_reader.pages[page_num].extract_text()

    # Display PDF content
    st.sidebar.markdown("### Contenu du fichier PDF :")
    st.sidebar.text_area("Contexte extrait du PDF", text, height=200)

# School data model with enriched information
school_data = pd.DataFrame([
    {"Nom": "Acad√©mie internationale Mohammed VI de l'aviation civile", "Sigle": "AIAC", "Ville": "Casablanca", "Sp√©cialit√©": "M√©tiers de l'aviation", "D√©bouch√©s": "Pilote, Contr√¥leur a√©rien"},
    {"Nom": "√âcole Hassania des travaux publics", "Sigle": "EHTP", "Ville": "Casablanca", "Sp√©cialit√©": "Polyvalente", "D√©bouch√©s": "Ing√©nieur Civil, Manager de projet"},
    {"Nom": "√âcole Mohammadia d'ing√©nieurs", "Sigle": "EMI", "Ville": "Rabat", "Sp√©cialit√©": "Polyvalente", "D√©bouch√©s": "Ing√©nieur M√©canique, Consultant technique"},
    {"Nom": "√âcoles nationales des sciences appliqu√©es", "Sigle": "ENSA", "Ville": "11 villes", "Sp√©cialit√©": "Polyvalente", "D√©bouch√©s": "D√©veloppeur logiciel, Ing√©nieur √©lectronique"},
    {"Nom": "Institut national des postes et t√©l√©communications", "Sigle": "INPT", "Ville": "Rabat", "Sp√©cialit√©": "T√©l√©communications", "D√©bouch√©s": "Ing√©nieur T√©l√©coms, Administrateur R√©seaux"},
])

# Display data
st.title("üéì Assistant d'Orientation - LLM")
st.markdown("**Explorez les √©coles et obtenez des r√©ponses adapt√©es avec un chatbot IA.**")

# School selection and details
selected_school = st.selectbox("Choisissez une √©cole :", school_data["Nom"])
school_info = school_data[school_data["Nom"] == selected_school].iloc[0]

# Display school details
st.subheader("üìç Informations sur l'√©cole")
st.markdown(f"**Nom :** {school_info['Nom']}")
st.markdown(f"**Ville :** {school_info['Ville']}")
st.markdown(f"**Sp√©cialit√© :** {school_info['Sp√©cialit√©']}")

st.subheader("üéØ D√©bouch√©s")
st.markdown(f"**D√©bouch√©s :** {school_info['D√©bouch√©s']}")

# Interaction with LLM
st.markdown("### üí¨ Posez une question :")
user_input = st.text_input("Votre question :", "")

if st.button("Envoyer"):
    if user_input.strip():
        with st.spinner("Chargement..."):
            try:
                # Combine question with school context
                message = f"L'utilisateur a s√©lectionn√© l'√©cole {school_info['Nom']} ({school_info['Ville']}). Question : {user_input}"
                st.session_state["messages"].append(HumanMessage(content=message))

                # Generate LLM response
                response = llm.invoke(st.session_state["messages"])

                # Add response to conversation history
                st.session_state["messages"].append(AIMessage(content=response.content))

                # Display response
                st.success("R√©ponse g√©n√©r√©e üéâ")
                st.markdown(f"**ü§ñ LLM :** {response.content}")
            except Exception as e:
                st.error(f"Une erreur s'est produite : {e}")
    else:
        st.warning("Veuillez entrer une question avant d'envoyer.")
